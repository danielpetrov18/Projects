spring:
  data-folder: knowledge_base  # This is where the pdf files will be kept (to be used as context for prompts).
  application:
    name: Spring RAG
  ai:
    ollama:
      base-url: http://ollama:11434 # Refer to the docker-compose file.
      # Ollama chat client configs
      chat:
        # All properties prefixed with spring.ai.ollama.chat.options can be overridden at runtime
        #   by adding a request specific Runtime Options to the Prompt call.
        options:
          model: llama3.1:8b # 8 billion parameters version.
          temperature: 0.7 # Increasing the temperature will make the model answer more creatively.
      # Ollama embedding configs
      embedding: 
        options:  
          model: nomic-embed-text:v1.5
    vectorstore:
      chroma:
        client:
          host: chromadb
          port: 8000 # That's the default one
        collection-name: OllamaRagData