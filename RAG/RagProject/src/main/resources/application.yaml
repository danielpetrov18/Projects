spring:
  application:
    name: RagProject
  main:
    allow-bean-definition-overriding: true
  data-folder: knowledge_base  # This is where the files will be kept (to be used as context for prompts).
  datasource:
    url: jdbc:postgresql://localhost:5432/rag
    username: admin
    password: admin
  ai:
    ollama:
      base-url: http://localhost:11434 # Refer to the docker-compose file.
      # Ollama chat client configs
      chat:
        # All properties prefixed with spring.ai.ollama.chat.options can be overridden at runtime
        #   by adding a request specific Runtime Options to the Prompt call.
        options:
          model: llama3.1:8b # 8 billion parameters version.
          temperature: 0.7 # Increasing the temperature will make the model answer more creatively.
      # Ollama embedding configs
      embedding: 
        options:  
          model: nomic-embed-text:v1.5
    vectorstore:
      pgvector:
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: 768 # https://ollama.com/library/nomic-embed-text
        initialize-schema: true
        #schema-validation: true
        #remove-existing-vector-store-table: false